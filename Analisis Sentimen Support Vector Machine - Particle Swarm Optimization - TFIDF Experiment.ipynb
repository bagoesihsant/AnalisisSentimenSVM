{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcc7a85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c03a7b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memuat Data\n",
    "df_data = pd.read_excel(\"D:/Bagoes/GitHub Repository/AnalisisSentimenSVM/Data/Data_Scraping_FemaleDaily_06032022_with_index.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc1ccd90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentimen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, reviewer, review, rating, sentimen]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menampilkan kolom Data\n",
    "df_data.head(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "389c0cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menghapus kolom data yang tidak digunakan\n",
    "df_data.drop([\"Unnamed: 0\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db513e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewer</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentimen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [reviewer, review, rating, sentimen]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menampilkan kolom Data\n",
    "df_data.head(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d1f7bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2276, 4)\n"
     ]
    }
   ],
   "source": [
    "# Menampilkan jumlah data dan kolom\n",
    "print(df_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "688c18b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menghapus data tertentu dalam data\n",
    "df_data.drop(index=[41, 82, 119, 139, 199, 213, 216, 236, 243, 276, 278, 317, 351, 379, 407, 444, 608, 707, 886, 945, 946, 1047, 1052, 1076, 1099, 1101, 1126, 1133, 1135, 1149, 1155, 1279, 1419, 1506, 1522, 1535, 1573, 1591, 1611, 1664, 1689, 1725, 1736, 1745, 1756, 1821, 1851, 1870, 1890, 1894, 1906, 1907, 1922, 1956, 1985, 1998, 2141, 2170, 2194, 2197, 2241, 2249, 2258], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab93351c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2213, 4)\n"
     ]
    }
   ],
   "source": [
    "# Menampilkan Jumlah Data\n",
    "print(df_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65829c12",
   "metadata": {},
   "source": [
    "1. Inisialisasi Fungsi Praproses (Preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4171349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import emoji\n",
    "\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10010d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk mengulang kata jika terdapat angka 2 dalam kata tersebut\n",
    "def extract_word_number(text):\n",
    "    extracted_char = \"\"\n",
    "    extra_char = \"\"\n",
    "    \n",
    "    # Check the text length\n",
    "    if len(text) > 1: \n",
    "        # Check if the string contain number 2 as a character\n",
    "        if \"2\" in text:\n",
    "            num_pos = text.index(\"2\")\n",
    "            # Check if theres another character after number 2 character\n",
    "            if len(text[(num_pos + 1):]) > 0:\n",
    "                extra_char = text[(num_pos + 1):]\n",
    "                extracted_char = [text[num] for num in range(num_pos)]\n",
    "                extracted_char = ''.join(extracted_char)\n",
    "                return text.replace(text, \"{0} {0}{1}\".format(extracted_char, extra_char))\n",
    "            else:\n",
    "                extra_char = \"\"\n",
    "                extracted_char = [text[num] for num in range(num_pos)]\n",
    "                extracted_char = ''.join(extracted_char)\n",
    "                return text.replace(text, \"{0} {0}{1}\".format(extracted_char, extra_char))\n",
    "        else:\n",
    "            return text\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8094cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk mengulang kata apabila ada angka 2 dalam bentuk superscript dalam kata\n",
    "def extract_word_superscript(text):\n",
    "    extracted_char = \"\"\n",
    "    extra_char = \"\"\n",
    "    \n",
    "    # Check the text length\n",
    "    if len(text) > 1: \n",
    "        # Check if the string contain number 2 as a character\n",
    "        if \"\\u00b2\" in text:\n",
    "            num_pos = text.index(\"\\u00b2\")\n",
    "            # Check if theres another character after number 2 character\n",
    "            if len(text[(num_pos + 1):]) > 0:\n",
    "                extra_char = text[(num_pos + 1):]\n",
    "                extracted_char = [text[num] for num in range(num_pos)]\n",
    "                extracted_char = ''.join(extracted_char)\n",
    "                return text.replace(text, \"{0} {0}{1}\".format(extracted_char, extra_char))\n",
    "            else:\n",
    "                extra_char = \"\"\n",
    "                extracted_char = [text[num] for num in range(num_pos)]\n",
    "                extracted_char = ''.join(extracted_char)\n",
    "                return text.replace(text, \"{0} {0}{1}\".format(extracted_char, extra_char))\n",
    "        else:\n",
    "            return text\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9b5549b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk menyamakan kata makeup dalam kalimat\n",
    "def make_up_replace(text):\n",
    "    if \"make up\" in text:\n",
    "        return text.replace(\"make up\", \"makeup\")\n",
    "    elif \"make upin\" in text:\n",
    "        return text.replace(\"make upin\", \"makeup\")\n",
    "    elif \"make upnya\" in text:\n",
    "        return text.replace(\"make upnya\", \"makeup\")\n",
    "    elif \"make-up\" in text:\n",
    "        return text.replace(\"make-up\", \"makeup\")\n",
    "    elif \"dimakeup\" in text:\n",
    "        return text.replace(\"dimakeup\", \"makeup\")\n",
    "    elif \"dimakeupin\" in text:\n",
    "        return text.replace(\"dimakeupin\", \"makeup\")\n",
    "    elif \"makeupnya\" in text:\n",
    "        return text.replace(\"makeupnya\", \"makeup\")\n",
    "    elif \"makeupny\" in text:\n",
    "        return text.replace(\"makeupny\", \"makeup\")\n",
    "    elif \"makeupku\" in text:\n",
    "        return text.replace(\"makeupku\", \"makeup\")\n",
    "    elif \"mekap\" in text:\n",
    "        return text.replace(\"mekap\", \"makeup\")\n",
    "    elif \"makeuonya\" in text:\n",
    "        return text.replace(\"makeuonya\", \"makeup\")\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3316dc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk menyamakan kata tzone dalam kalimat\n",
    "def t_zone_replace(text):\n",
    "    if \"t zone\" in text:\n",
    "        return text.replace(\"t zone\", \"tzone\")\n",
    "    elif \"t z\" in text:\n",
    "        return text.replace(\"t z\", \"tzone\")\n",
    "    elif \"t zonenya\" in text:\n",
    "        return text.replace(\"t zonenya\", \"tzone\")\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1011f80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk menyamakan kata bbceam dalam kalimat\n",
    "def bb_cream_replace(text):\n",
    "    if \"bb cream\" in text:\n",
    "        return text.replace(\"bb cream\", \"bbcream\")\n",
    "    else:\n",
    "        return text    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "078793fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk menyamakan kata cccream dalam kalimat\n",
    "def cc_cream_replace(text):\n",
    "    if \"cc cream\" in text:\n",
    "        return text.replace(\"cc cream\", \"cccream\")\n",
    "    else:\n",
    "        return text    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eec6d99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk menyamakan kata dceram dalam kalimat\n",
    "def dd_cream_replace(text):\n",
    "    if \"dd cream\" in text:\n",
    "        return text.replace(\"dd cream\", \"ddcream\")\n",
    "    else:\n",
    "        return text    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61812533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk menyamakan kata touchup dalam kalimat\n",
    "def touch_up_replace(text):\n",
    "    if \"touch up\" in text:\n",
    "        return text.replace(\"touch up\", \"touchup\")\n",
    "    elif \"ngeretouch\" in text:\n",
    "        return text.replace(\"ngeretouch\", \"touchup\")\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7410c890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk menyamakan kata breakout dalam kalimat\n",
    "def break_out_replace(text):\n",
    "    if \"break out\" in text:\n",
    "        return text.replace(\"break out\", \"breakout\")\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a51f44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk menyamakan kata skincare dalam kalimat\n",
    "def skin_care_replace(text):\n",
    "    if \"skin care\" in text:\n",
    "        return text.replace(\"skin care\", \"skincare\")\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b6e1d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk menyamakan kata sunscreen dalam kalimat\n",
    "def sun_screen_replace(text):\n",
    "    if \"sun screen\" in text:\n",
    "        return text.replace(\"sun screen\", \"sunscreen\")\n",
    "    elif \"sunscreenku\" in text:\n",
    "        return text.replace(\"sunscreenku\", \"sunscreen\")\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9af0d0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk mengubah seluruh karakter dalam kalimat menjadi huruf kecil (lowercase)\n",
    "def case_folding(message):\n",
    "    return message.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a998bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk menghapus tanda baca dalam kalimat\n",
    "def del_punctuation(message):\n",
    "    for punc in string.punctuation:\n",
    "        if punc in message:\n",
    "            message = message.replace(punc, ' ')\n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf93d337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk menghapus angka dalam kalimat\n",
    "def del_number(message):\n",
    "    regex = r'\\d+'\n",
    "    return ' '.join(re.sub(regex, \"\", message).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee22defa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk menghapus emotikon dalam kalimat\n",
    "def del_emoticon(message):\n",
    "    return emoji.replace_emoji(message, replace=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e124a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk menghapus kata dengan jumlah huruf yang lebih dari satu dan berdekatan \n",
    "def remove_repeated_char(text):\n",
    "    return re.sub(r'(\\w)\\1+', r'\\1', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3bf1f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk mengubah kata yang menggunakan angka untuk membuat kata berulang\n",
    "def replace_repeat_word_num(message):\n",
    "    split_msg = [word.replace(word, extract_word_number(word)) for word in message.split()]\n",
    "    return \" \".join(split_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1680478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk mengubah kata yang menggunakan angka dalam bentuk superscript untuk membuat kata berulang\n",
    "def replace_repeat_word_superscript(message):\n",
    "    split_msg = [word.replace(word, extract_word_superscript(word)) for word in message.split()]\n",
    "    return \" \".join(split_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "270ea02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk mengubah kata yang memiliki karakter yang sama dan berdekatan dengan jumlah lebih dari satu dalam kalimat\n",
    "def normalisasi_kata_redundan(message):\n",
    "    return remove_repeated_char(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d01e3e4",
   "metadata": {},
   "source": [
    "2. Memuat Corpus Yang Akan Digunakan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2a6a717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c4e299fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memuat Daftar kata dengan jumlah huruf yang sama lebih dari satu dan berdekatan\n",
    "reader_kata_dua_karakter = csv.reader(open(r\"D:/Bagoes/GitHub Repository/AnalisisSentimenSVM/Data/kata_dua_karakter.csv\", \"r\"))\n",
    "\n",
    "dict_kata_dua_karakter = {row[0]:row[1] for row in reader_kata_dua_karakter if row and row[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d359ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memuat daftar kata istilah asing yang tediri dari satu kata\n",
    "reader_satu_kata = csv.reader(open(r\"D:/Bagoes/GitHub Repository/AnalisisSentimenSVM/Data/translasi_satu_kata.csv\", \"r\"))\n",
    "\n",
    "dict_translasi_satu_kata = {row[0]:row[1] for row in reader_satu_kata if row and row[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be626339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memuat daftar kalimat dengan istilah asing\n",
    "reader_lebih_satu_kata = csv.reader(open(r\"D:/Bagoes/GitHub Repository/AnalisisSentimenSVM/Data/translasi_lebih_satu_kata.csv\", \"r\"))\n",
    "\n",
    "result_lebih_satu_kata = {row[0]:row[1] for row in reader_lebih_satu_kata if row and row[0]}\n",
    "\n",
    "# Mengurutkan daftar kalimat istilah asing sesuai dengan panjang kalimat\n",
    "\n",
    "# sorting using sorted()\n",
    "# lambda fnc. to render logic \n",
    "list_lebih_satu_kata = sorted(list(result_lebih_satu_kata.items()), key = lambda key : len(key[0]), reverse=True)\n",
    "\n",
    "# reordering corpus dictionary translasi bahasa lebih satu kata\n",
    "dict_lebih_satu_kata = {val[0] : val[1] for val in list_lebih_satu_kata}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c347a51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memuat daftar kata bahasa alay\n",
    "df_kamus_bahasa_alay = pd.read_csv(r\"D:/Bagoes/GitHub Repository/AnalisisSentimenSVM/Data/colloquial-indonesian-lexicon.csv\")\n",
    "\n",
    "# Membuat Kamus Bahasa Alay\n",
    "list_kata_slang = []\n",
    "\n",
    "for kata_slang in df_kamus_bahasa_alay[\"slang\"]:\n",
    "    list_kata_slang.append(kata_slang)\n",
    "\n",
    "list_kata_formal = []\n",
    "\n",
    "for kata_formal in df_kamus_bahasa_alay[\"formal\"]:\n",
    "    list_kata_formal.append(kata_formal)\n",
    "\n",
    "dict_bahasa_alay = {}\n",
    "\n",
    "for key, value in zip(df_kamus_bahasa_alay[\"slang\"], df_kamus_bahasa_alay[\"formal\"]):\n",
    "    if dict_bahasa_alay.get(key) == None:\n",
    "        dict_bahasa_alay.update({key:value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "14b79dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memuat daftar kata yang mengandung typo (salah dalam penulisan)\n",
    "reader_koreksi_kata = csv.reader(open(r\"D:/Bagoes/GitHub Repository/AnalisisSentimenSVM/Data/koreksi_kata.csv\", \"r\"))\n",
    "\n",
    "dict_koreksi_kata = {row[0]:row[1] for row in reader_koreksi_kata if row and row[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c56bb6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memuat daftar kata yang merupakan stopwords (kata redundan)\n",
    "factory = StopWordRemoverFactory()\n",
    "stopwords_indonesia = factory.get_stop_words()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66ef8f0",
   "metadata": {},
   "source": [
    "3. Membuat Fungsi Untuk Menggunakan Corpus Yang Telah Dimuat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "898537c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk memeriksa apakah token terdapat dalam daftar kata dengan dua karakter yang sama berjumlah lebih dari satu dan berdekatan\n",
    "def check_kata_dua_karakter(text):\n",
    "    for key, val in dict_kata_dua_karakter.items():\n",
    "        if text == key:\n",
    "            text = text.replace(text, dict_kata_dua_karakter.get(key))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a40e8e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk memeriksa apakah token terdapat dalam daftar kata yang akan di translasi\n",
    "def check_translasi_satu_kata(text):\n",
    "    for key, val in dict_translasi_satu_kata.items():\n",
    "        if text == key:\n",
    "            text = text.replace(text, dict_translasi_satu_kata.get(key))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bca4beae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk memeriksa apakah token terdapat dalam daftar kata yang memiliki typo (salah penulisan)\n",
    "def check_koreksi_kata(text):\n",
    "    for key, val in dict_koreksi_kata.items():\n",
    "        if text == key:\n",
    "            text = text.replace(text, dict_koreksi_kata.get(key))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "574ac03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk memeriksa apakah token terdapat dalam daftar kata slang (alay)\n",
    "def check_kata_alay(text):\n",
    "    for key, val in dict_bahasa_alay.items():\n",
    "        if text == key:\n",
    "            text = text.replace(text, dict_bahasa_alay.get(key))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ac1953c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk melakukan normalisasi kalimat menggunakan daftar kata dengan dua karakter yang sama berjumlah lebih dari satu dan berdekatan\n",
    "def normalisasi_kata_dua_karakter(message):\n",
    "    split_text = [check_kata_dua_karakter(text) for text in message.split()]\n",
    "    return \" \".join(split_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "17b4bf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk melakukan normalisasi kalimat menggunakan daftar kalimat yang akan di translasi\n",
    "def normalisasi_translasi_kalimat(message):\n",
    "    for key, val in dict_lebih_satu_kata.items():\n",
    "        if key in message:\n",
    "            message = message.replace(key, dict_lebih_satu_kata.get(key))\n",
    "    return message  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f59c0371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk melakukan normalisasi kalimat menggunakan daftar kata yang akan di translasi\n",
    "def normalisasi_translasi_kata(message):\n",
    "    split_text = [check_translasi_satu_kata(text) for text in message.split()]\n",
    "    return \" \".join(split_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "20ec59d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk melakukan normalisasi kalimat menggunakan daftar kata yang memiliki typo (salah penulisan)\n",
    "def normalisasi_koreksi_kata(message):\n",
    "    split_text = [check_koreksi_kata(text) for text in message.split()]\n",
    "    return \" \".join(split_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4abc3d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk melakukan normalisasi kalimat menggunakan daftar kata slang (alay)\n",
    "def normalisasi_kata_alay(message):\n",
    "    split_text = [check_kata_alay(text) for text in message.split()]\n",
    "    return \" \".join(split_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bcd64cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk menghapus stopwords menggunakan daftar stopwords\n",
    "def del_stopwords(message):\n",
    "    split_text = [text for text in message.split() if text not in stopwords_indonesia]\n",
    "    return \" \".join(split_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f22bb807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memuat Stemmer\n",
    "stem_factory = StemmerFactory()\n",
    "stemmer = stem_factory.create_stemmer()\n",
    "\n",
    "# Fungsi untuk melakukan stemming\n",
    "def stem_words(message):\n",
    "    split_text = [stemmer.stem(text) for text in message.split()]\n",
    "    return \" \".join(split_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "74c5eef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat mapping untuk label data\n",
    "label = {'positif' : 1, 'negatif' : 2}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72e1c5a",
   "metadata": {},
   "source": [
    "4. Tahapan Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ccf78373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melakukan tahapan preprocessing\n",
    "# 1. Case Folding\n",
    "df_data['review'] = df_data['review'].apply(case_folding)\n",
    "# 2. Delete Punctuation\n",
    "df_data['review'] = df_data['review'].apply(del_punctuation)\n",
    "# 3. Delete Emoticon\n",
    "df_data['review'] = df_data['review'].apply(del_emoticon)\n",
    "# 4. Normalisasi Kata Makeup\n",
    "df_data['review'] = df_data['review'].apply(make_up_replace)\n",
    "# 5. Normalisasi Kata TZone\n",
    "df_data['review'] = df_data['review'].apply(t_zone_replace)\n",
    "# 6. Normalisasi Kata BBCream\n",
    "df_data['review'] = df_data['review'].apply(bb_cream_replace)\n",
    "# 7. Normalisasi Kata CCCream\n",
    "df_data['review'] = df_data['review'].apply(cc_cream_replace)\n",
    "# 8. Normalisasi Kata DDCream\n",
    "df_data['review'] = df_data['review'].apply(dd_cream_replace)\n",
    "# 9. Normalisasi Kata Touchup\n",
    "df_data['review'] = df_data['review'].apply(touch_up_replace)\n",
    "# 10. Normalisasi Kata Breakout\n",
    "df_data['review'] = df_data['review'].apply(break_out_replace)\n",
    "# 11. Normalisasi Kata Skin Care\n",
    "df_data['review'] = df_data['review'].apply(skin_care_replace)\n",
    "# 12. Normalisasi Kata Sun Screen\n",
    "df_data['review'] = df_data['review'].apply(sun_screen_replace)\n",
    "# 13. Normalisasi Kata Berulang Dengan Angka\n",
    "df_data['review'] = df_data['review'].apply(replace_repeat_word_num)\n",
    "# 14. Normalisasi Kata Berulang Dengan Angka (Superscript)\n",
    "df_data['review'] = df_data['review'].apply(replace_repeat_word_superscript)\n",
    "# 15. Delete Number\n",
    "df_data['review'] = df_data['review'].apply(del_number)\n",
    "# 16. Normalisasi Kata Dua Karakter Berjumlah Lebih Dari Satu dan Berdekatan\n",
    "df_data['review'] = df_data['review'].apply(remove_repeated_char)\n",
    "df_data['review'] = df_data['review'].apply(normalisasi_kata_dua_karakter)\n",
    "# 17. Normalisasi Translasi Kalimat\n",
    "df_data['review'] = df_data['review'].apply(normalisasi_translasi_kalimat)\n",
    "# 18. Normalisasi Translasi Kata\n",
    "df_data['review'] = df_data['review'].apply(normalisasi_translasi_kata)\n",
    "# 19. Normalisasi Koreksi Kata\n",
    "df_data['review'] = df_data['review'].apply(normalisasi_koreksi_kata)\n",
    "# 20. Normalisasi Kata Slang (Alay)\n",
    "df_data['review'] = df_data['review'].apply(normalisasi_kata_alay)\n",
    "# 21. Delete Stopwords\n",
    "df_data['review'] = df_data['review'].apply(del_stopwords)\n",
    "# 22. Normalisasi Kata (Stemming)\n",
    "df_data['review'] = df_data['review'].apply(stem_words)\n",
    "# 23. Normalisasi Label Data\n",
    "df_data[\"sentimen\"] = df_data[\"sentimen\"].map(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4517e56f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewer</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentimen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shafiranri</td>\n",
       "      <td>makeup tahan kulit lembut pori pori tekstur ge...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amaliaarumsari</td>\n",
       "      <td>primer populer banget telat coba habis pakai k...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>maryamst</td>\n",
       "      <td>primer bahan dasar silikon bikin wajah halus a...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Virzqia</td>\n",
       "      <td>wew banget produk samar pori bantu bikin makeu...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aviyanti15</td>\n",
       "      <td>primer makeup coba tekstur kayak gel silikon p...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2271</th>\n",
       "      <td>unibayyinah</td>\n",
       "      <td>tekstur gel minyak serap kulit lumayan cepat s...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2272</th>\n",
       "      <td>eneng.peni</td>\n",
       "      <td>primer silikon murah kualitas bagus pakai prim...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2273</th>\n",
       "      <td>inedewi</td>\n",
       "      <td>makeup primer warna kemas fresh banget cerah b...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2274</th>\n",
       "      <td>princessvie</td>\n",
       "      <td>bilang imitasi brand belah pakai aplikasi make...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2275</th>\n",
       "      <td>imeldanababan</td>\n",
       "      <td>suka pakai primer bikin kulit pori non comedog...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2213 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            reviewer                                             review  \\\n",
       "0         shafiranri  makeup tahan kulit lembut pori pori tekstur ge...   \n",
       "1     amaliaarumsari  primer populer banget telat coba habis pakai k...   \n",
       "2           maryamst  primer bahan dasar silikon bikin wajah halus a...   \n",
       "3            Virzqia  wew banget produk samar pori bantu bikin makeu...   \n",
       "4         Aviyanti15  primer makeup coba tekstur kayak gel silikon p...   \n",
       "...              ...                                                ...   \n",
       "2271     unibayyinah  tekstur gel minyak serap kulit lumayan cepat s...   \n",
       "2272      eneng.peni  primer silikon murah kualitas bagus pakai prim...   \n",
       "2273         inedewi  makeup primer warna kemas fresh banget cerah b...   \n",
       "2274     princessvie  bilang imitasi brand belah pakai aplikasi make...   \n",
       "2275   imeldanababan  suka pakai primer bikin kulit pori non comedog...   \n",
       "\n",
       "      rating  sentimen  \n",
       "0          5         1  \n",
       "1          4         1  \n",
       "2          5         1  \n",
       "3          5         1  \n",
       "4          4         1  \n",
       "...      ...       ...  \n",
       "2271       4         1  \n",
       "2272       3         1  \n",
       "2273       4         1  \n",
       "2274       4         1  \n",
       "2275       4         1  \n",
       "\n",
       "[2213 rows x 4 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd69a60",
   "metadata": {},
   "source": [
    "5. Tahapan Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ab5d7c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import Library\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7173e1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Memisahkan data train dengan label\n",
    "X = df_data[\"review\"]\n",
    "y = df_data[\"sentimen\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1cf3fec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    makeup tahan kulit lembut pori pori tekstur ge...\n",
       "1    primer populer banget telat coba habis pakai k...\n",
       "2    primer bahan dasar silikon bikin wajah halus a...\n",
       "3    wew banget produk samar pori bantu bikin makeu...\n",
       "4    primer makeup coba tekstur kayak gel silikon p...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "caec94c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2213\n"
     ]
    }
   ],
   "source": [
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5326d1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2213\n"
     ]
    }
   ],
   "source": [
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "df2fe885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memuat Corpus Tambahan Untuk TF - IDF\n",
    "opinion_words_file = open(r\"D:/Bagoes/Jupyter/Data/id_opinion_words/negative.txt\", \"r\")\n",
    "opinion_words_content = opinion_words_file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "516bece3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(opinion_words_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "63fa8fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menghapus karakter enter\n",
    "opinion_words_negatif = []\n",
    "for val in opinion_words_content:\n",
    "    opinion_words_negatif.append(del_punctuation(val.replace(\"\\n\", \"\").lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2ae406ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abnormal',\n",
       " 'absurd',\n",
       " 'acak',\n",
       " 'acak acakan',\n",
       " 'acuh',\n",
       " 'acuh tak acuh',\n",
       " 'adiktif',\n",
       " 'adil',\n",
       " 'agresi',\n",
       " 'agresif',\n",
       " 'agresor',\n",
       " 'aib',\n",
       " 'air terjun',\n",
       " 'akurat',\n",
       " 'alarm',\n",
       " 'alasan',\n",
       " 'alat permainan',\n",
       " 'alergi',\n",
       " 'alergik',\n",
       " 'amat ketakutan',\n",
       " 'amat panas',\n",
       " 'ambigu',\n",
       " 'ambivalen',\n",
       " 'ambivalensi',\n",
       " 'amoral',\n",
       " 'amoralitas',\n",
       " 'ampun',\n",
       " 'amuk',\n",
       " 'anak nakal',\n",
       " 'anak yatim',\n",
       " 'anarki',\n",
       " 'anarkis',\n",
       " 'anarkisme',\n",
       " 'ancaman',\n",
       " 'aneh',\n",
       " 'aneh lagi',\n",
       " 'anehnya',\n",
       " 'angkuh',\n",
       " 'angriness',\n",
       " 'anjing',\n",
       " 'anjlok',\n",
       " 'anomali',\n",
       " 'antagonis',\n",
       " 'antagonisme',\n",
       " 'antek',\n",
       " 'anti ',\n",
       " 'anti amerika',\n",
       " 'anti israel',\n",
       " 'anti kita',\n",
       " 'anti pendudukan',\n",
       " 'anti proliferasi',\n",
       " 'anti putih',\n",
       " 'anti semit',\n",
       " 'antipati',\n",
       " 'antisosial',\n",
       " 'antitesis',\n",
       " 'apak',\n",
       " 'apati',\n",
       " 'apatis',\n",
       " 'apek',\n",
       " 'apokaliptik',\n",
       " 'apologis',\n",
       " 'argumentatif',\n",
       " 'artinya jika',\n",
       " 'asam',\n",
       " 'asap',\n",
       " 'asem',\n",
       " 'asing',\n",
       " 'astaghfirullah',\n",
       " 'asusila',\n",
       " 'awan',\n",
       " 'awas',\n",
       " 'babi',\n",
       " 'badai',\n",
       " 'bahan tertawaan',\n",
       " 'bahaya',\n",
       " 'bajingan',\n",
       " 'baju kotor',\n",
       " 'balas dendam',\n",
       " 'bandel',\n",
       " 'bandot',\n",
       " 'bangkrut',\n",
       " 'bantingan',\n",
       " 'banyak sekali',\n",
       " 'barang ganjil',\n",
       " 'barbar',\n",
       " 'basi',\n",
       " 'bau',\n",
       " 'bawahan',\n",
       " 'bebal',\n",
       " 'beban',\n",
       " 'bejat',\n",
       " 'bekas',\n",
       " 'bekas luka',\n",
       " 'bekas roda',\n",
       " 'beku',\n",
       " 'belah',\n",
       " 'belum dewasa',\n",
       " 'belum dicoba',\n",
       " 'belum dikonfirmasi',\n",
       " 'belum pasti',\n",
       " 'belum selesai',\n",
       " 'benar benar',\n",
       " 'bencana',\n",
       " 'bencana alam',\n",
       " 'benci',\n",
       " 'bengah',\n",
       " 'bengis',\n",
       " 'bengkak',\n",
       " 'bengkeng',\n",
       " 'bengkok',\n",
       " 'benjolan',\n",
       " 'bentrokan',\n",
       " 'beracun',\n",
       " 'beradab',\n",
       " 'berakhir',\n",
       " 'berang',\n",
       " 'berani',\n",
       " 'berantakan',\n",
       " 'berat',\n",
       " 'berat sebelah',\n",
       " 'berawan',\n",
       " 'berbahaya',\n",
       " 'berbatu batu',\n",
       " 'berbau',\n",
       " 'berbeda',\n",
       " 'berbisa',\n",
       " 'berbohong',\n",
       " 'berbuat curang',\n",
       " 'berbuat jahat',\n",
       " 'berbuat salah',\n",
       " 'berbuih',\n",
       " 'bercacat',\n",
       " 'berdalih',\n",
       " 'berdarah',\n",
       " 'berdasar',\n",
       " 'berdaya',\n",
       " 'berdebar',\n",
       " 'berdebat',\n",
       " 'berdebu',\n",
       " 'berdengung',\n",
       " 'berdenyut',\n",
       " 'berdenyut denyut',\n",
       " 'berderak',\n",
       " 'berderit',\n",
       " 'berdetak',\n",
       " 'berdokumen',\n",
       " 'berdosa',\n",
       " 'berduka',\n",
       " 'berduri',\n",
       " 'berdusta',\n",
       " 'berebut',\n",
       " 'bergairah',\n",
       " 'bergegas',\n",
       " 'bergelombang',\n",
       " 'bergeming',\n",
       " 'bergerak',\n",
       " 'bergerak lambat',\n",
       " 'bergerigi',\n",
       " 'bergetar',\n",
       " 'bergolak',\n",
       " 'bergulat',\n",
       " 'berhaluan kiri',\n",
       " 'berisiko',\n",
       " 'berita palsu',\n",
       " 'berjangkit',\n",
       " 'berjuang',\n",
       " 'berkarat',\n",
       " 'berkata tanpa berpikir',\n",
       " 'berkedip',\n",
       " 'berkejut',\n",
       " 'berkenan',\n",
       " 'berkeping keping',\n",
       " 'berkeras pendirian',\n",
       " 'berkeringat',\n",
       " 'berkerut',\n",
       " 'berkhayal',\n",
       " 'berkilat',\n",
       " 'berkilau',\n",
       " 'berkolusi',\n",
       " 'berkonflik',\n",
       " 'berkubang',\n",
       " 'berkurang',\n",
       " 'berlangganan',\n",
       " 'berlebihan',\n",
       " 'berlemak',\n",
       " 'berlengah lengah',\n",
       " 'berlepotan',\n",
       " 'berliku liku',\n",
       " 'berlumpur',\n",
       " 'bermain berlebih lebihan',\n",
       " 'bermasalah',\n",
       " 'berminyak',\n",
       " 'bermoral',\n",
       " 'bermuka dua',\n",
       " 'bermuram',\n",
       " 'bermuram durja',\n",
       " 'bermusuhan',\n",
       " 'bermutu rendah',\n",
       " 'bernasib buruk',\n",
       " 'bernoda kotor',\n",
       " 'berongga',\n",
       " 'berperang',\n",
       " 'berpura pura',\n",
       " 'berputus asa',\n",
       " 'bersaing',\n",
       " 'bersakit',\n",
       " 'bersanding',\n",
       " 'bersedih',\n",
       " 'bersekongkol',\n",
       " 'berselang',\n",
       " 'berselisih',\n",
       " 'bersemangat',\n",
       " 'bersenandung',\n",
       " 'berserakan',\n",
       " 'bersetubuh',\n",
       " 'bersisik',\n",
       " 'bertele tele',\n",
       " 'bertemu',\n",
       " 'bertengkar',\n",
       " 'bertentangan',\n",
       " 'berteriak',\n",
       " 'bertindak tidak pantas',\n",
       " 'bertingkah',\n",
       " 'bertubuh kecil',\n",
       " 'berukuran terlalu kecil',\n",
       " 'berumur pendek',\n",
       " 'berwajah dua',\n",
       " 'biadab',\n",
       " 'bias',\n",
       " 'biasa',\n",
       " 'biasa biasa saja',\n",
       " 'bid ah',\n",
       " 'bikinan',\n",
       " 'bimbang',\n",
       " 'binasa',\n",
       " 'bingung',\n",
       " 'bisa ular',\n",
       " 'bising',\n",
       " 'blunder',\n",
       " 'bobrok',\n",
       " 'bocor',\n",
       " 'bodoh',\n",
       " 'bohong',\n",
       " 'bom',\n",
       " 'boneka',\n",
       " 'boros',\n",
       " 'bosan',\n",
       " 'botak',\n",
       " 'brutal',\n",
       " 'bual',\n",
       " 'buar',\n",
       " 'buas',\n",
       " 'budak',\n",
       " 'bug',\n",
       " 'bukan kepalang',\n",
       " 'buntu',\n",
       " 'bunuh diri',\n",
       " 'buram',\n",
       " 'buritan',\n",
       " 'buronan',\n",
       " 'buruk',\n",
       " 'buruk sekali',\n",
       " 'busuk',\n",
       " 'buta',\n",
       " 'buta huruf',\n",
       " 'cabul',\n",
       " 'cacat',\n",
       " 'cacian',\n",
       " 'calo',\n",
       " 'cambuk',\n",
       " 'canggung',\n",
       " 'cara',\n",
       " 'cari perkara',\n",
       " 'carut marut',\n",
       " 'cebol',\n",
       " 'cedera',\n",
       " 'cekcok',\n",
       " 'cekung',\n",
       " 'celaan',\n",
       " 'celah',\n",
       " 'celaka',\n",
       " 'cemas',\n",
       " 'cemberut',\n",
       " 'cemburu',\n",
       " 'cemooh',\n",
       " 'cemoohan',\n",
       " 'cenderung',\n",
       " 'cengeng',\n",
       " 'cengking',\n",
       " 'cercaan',\n",
       " 'cerdik',\n",
       " 'cerewet',\n",
       " 'ceroboh',\n",
       " 'compang camping',\n",
       " 'corengan',\n",
       " 'cukup',\n",
       " 'curam',\n",
       " 'curang',\n",
       " 'curiga',\n",
       " 'dancok',\n",
       " 'dangkal',\n",
       " 'deadline',\n",
       " 'debu',\n",
       " 'defensif',\n",
       " 'degenerasi',\n",
       " 'degradasi',\n",
       " 'dehumanisasi',\n",
       " 'delusi',\n",
       " 'demam',\n",
       " 'demoralisasi',\n",
       " 'dendam',\n",
       " 'dengan mencemoohkan',\n",
       " 'dengan mendapat malapetaka',\n",
       " 'dengan mengagetkan',\n",
       " 'dengan menghina',\n",
       " 'dengan menyedihkan',\n",
       " 'dengan menyesal',\n",
       " 'dengan panas',\n",
       " 'dengan penuh ketakutan',\n",
       " 'dengan rasa curiga',\n",
       " 'dengan rasa hina',\n",
       " 'dengan remeh temeh',\n",
       " 'dengan sedih',\n",
       " 'dengan segan',\n",
       " 'dengan sengit',\n",
       " 'dengan sia sia',\n",
       " 'dengan suara keras',\n",
       " 'dengan sukar',\n",
       " 'dengan terbahak bahak',\n",
       " 'dengan tidak senang',\n",
       " 'dengki',\n",
       " 'depresi',\n",
       " 'derita',\n",
       " 'desis',\n",
       " 'destruktif',\n",
       " 'diam',\n",
       " 'diam diam',\n",
       " 'dibakar',\n",
       " 'dibanjiri',\n",
       " 'dibantai',\n",
       " 'dibenarkan',\n",
       " 'dibenci',\n",
       " 'dibesar besarkan',\n",
       " 'dibuang',\n",
       " 'dibuat buat',\n",
       " 'dicela',\n",
       " 'dicerca',\n",
       " 'dicuci',\n",
       " 'dicuri',\n",
       " 'didanai',\n",
       " 'diganggu',\n",
       " 'dihaluskan',\n",
       " 'dihentikan',\n",
       " 'dihibur',\n",
       " 'dihukum',\n",
       " 'dijauhi',\n",
       " 'dijelaskan',\n",
       " 'dikaburkan',\n",
       " 'dikenakan',\n",
       " 'dikorbankan',\n",
       " 'diktator',\n",
       " 'diktatoris',\n",
       " 'dilapisi gula',\n",
       " 'dilecehkan',\n",
       " 'dilema',\n",
       " 'dilenyapkan',\n",
       " 'dimaafkan',\n",
       " 'dimarahi',\n",
       " 'dimengerti',\n",
       " 'dingin',\n",
       " 'diperangi',\n",
       " 'diperkosa',\n",
       " 'diperlakukan dengan buruk',\n",
       " 'dipermainkan',\n",
       " 'dipertanyakan',\n",
       " 'dipikirkan',\n",
       " 'dirampas',\n",
       " 'diremehkan',\n",
       " 'dirugikan',\n",
       " 'disalahgunakan',\n",
       " 'disalahpahami',\n",
       " 'disayangkan',\n",
       " 'disebut sebut',\n",
       " 'disederhanakan',\n",
       " 'disengaja',\n",
       " 'disengketakan',\n",
       " 'disiram',\n",
       " 'diskredit',\n",
       " 'diskriminasi',\n",
       " 'diskriminatif',\n",
       " 'disorient',\n",
       " 'disproporsional',\n",
       " 'distorsi',\n",
       " 'ditakdirkan',\n",
       " 'ditinggalkan',\n",
       " 'ditipu',\n",
       " 'ditolak',\n",
       " 'dogmatis',\n",
       " 'dominan',\n",
       " 'dongkol',\n",
       " 'dosa',\n",
       " 'downgrade',\n",
       " 'drastis',\n",
       " 'drop out',\n",
       " 'dua wajah',\n",
       " 'dugaan',\n",
       " 'duka',\n",
       " 'dukun',\n",
       " 'dumping',\n",
       " 'dungu',\n",
       " 'duniawi',\n",
       " 'dupa',\n",
       " 'durhaka',\n",
       " 'duri',\n",
       " 'dusta',\n",
       " 'dusun',\n",
       " 'dwimakna',\n",
       " 'edan',\n",
       " 'egois',\n",
       " 'egoisme',\n",
       " 'egomania',\n",
       " 'egosentris',\n",
       " 'ejek',\n",
       " 'ejekan',\n",
       " 'ekonomis',\n",
       " 'eksploitasi',\n",
       " 'eksploitatif',\n",
       " 'eksplosif',\n",
       " 'ekstremis',\n",
       " 'enggan',\n",
       " 'enggan membantu',\n",
       " 'erosi',\n",
       " 'fana',\n",
       " 'fanatik',\n",
       " 'fanatisme',\n",
       " 'fantastis',\n",
       " 'fasis',\n",
       " 'fasisme',\n",
       " 'fatal',\n",
       " 'fiksi',\n",
       " 'fitnah',\n",
       " 'fitnahan',\n",
       " 'fobia',\n",
       " 'friksi',\n",
       " 'frustasi',\n",
       " 'frustrasi',\n",
       " 'fundamentalis',\n",
       " 'fundamentalisme',\n",
       " 'ga jelas',\n",
       " 'ga karuan',\n",
       " 'ga peka',\n",
       " 'gadungan',\n",
       " 'gagal',\n",
       " 'gagap',\n",
       " 'gaib',\n",
       " 'galak',\n",
       " 'ganas',\n",
       " 'gangguan',\n",
       " 'ganjil',\n",
       " 'ganti rugi',\n",
       " 'gantung',\n",
       " 'garang',\n",
       " 'garis keras',\n",
       " 'garu',\n",
       " 'gasang',\n",
       " 'gatal',\n",
       " 'gegabah',\n",
       " 'gejala',\n",
       " 'gelandangan',\n",
       " 'gelap',\n",
       " 'gelisah',\n",
       " 'gelora',\n",
       " 'gembar gembor',\n",
       " 'gendut',\n",
       " 'genit',\n",
       " 'genosida',\n",
       " 'genting',\n",
       " 'gerah',\n",
       " 'geram',\n",
       " 'gerombolan',\n",
       " 'gesekan',\n",
       " 'gesper',\n",
       " 'getah',\n",
       " 'getaran',\n",
       " 'giat',\n",
       " 'gigih',\n",
       " 'gigil',\n",
       " 'gila',\n",
       " 'gila hormat',\n",
       " 'gila ketakutan',\n",
       " 'gila gilaan',\n",
       " 'godaan',\n",
       " 'goreng',\n",
       " 'goresan',\n",
       " 'gosip',\n",
       " 'goyah',\n",
       " 'goyangan',\n",
       " 'gua',\n",
       " 'gugup',\n",
       " 'gurun',\n",
       " 'gusar',\n",
       " 'habis',\n",
       " 'hak milik',\n",
       " 'hal merendahkan diri',\n",
       " 'hal tidak dimengerti',\n",
       " 'halangan',\n",
       " 'hama',\n",
       " 'hambatan',\n",
       " 'hampir',\n",
       " 'hampir mati',\n",
       " 'hancur',\n",
       " 'hang',\n",
       " 'haram',\n",
       " 'harga di atas',\n",
       " 'hasutan',\n",
       " 'haus',\n",
       " 'haus darah',\n",
       " 'hedon',\n",
       " 'hedonistik',\n",
       " 'hegemoni',\n",
       " 'hegemonisme',\n",
       " 'hemat',\n",
       " 'hidung belang',\n",
       " 'hina',\n",
       " 'hingar bingar',\n",
       " 'hiruk pikuk',\n",
       " 'histeri',\n",
       " 'histeria',\n",
       " 'histeris',\n",
       " 'hujat',\n",
       " 'hukuman',\n",
       " 'hukuman penjara',\n",
       " 'hukuman setimpal',\n",
       " 'hutang',\n",
       " 'iblis',\n",
       " 'idiot',\n",
       " 'igauan',\n",
       " 'ih',\n",
       " 'ikut campur',\n",
       " 'ilegal',\n",
       " 'iluminati',\n",
       " 'ilusi',\n",
       " 'imajiner',\n",
       " 'imperialis',\n",
       " 'impoten',\n",
       " 'impulsif',\n",
       " 'individualis',\n",
       " 'indoktrinasi',\n",
       " 'infeksi',\n",
       " 'inferioritas',\n",
       " 'inflamasi',\n",
       " 'inflasi',\n",
       " 'ingusan',\n",
       " 'inkompeten',\n",
       " 'inkompetensi',\n",
       " 'inkonsistensi',\n",
       " 'inkonstitusionil',\n",
       " 'insensitively',\n",
       " 'interupsi',\n",
       " 'intimidasi',\n",
       " 'intrusi',\n",
       " 'invasif',\n",
       " 'irasional',\n",
       " 'irasionalitas',\n",
       " 'iri',\n",
       " 'iritasi',\n",
       " 'ironi',\n",
       " 'ironis',\n",
       " 'ironisnya',\n",
       " 'isolasi',\n",
       " 'istirahat',\n",
       " 'isu',\n",
       " 'jadah',\n",
       " 'jahanam',\n",
       " 'jahat',\n",
       " 'jalan buntu',\n",
       " 'jalan keluar',\n",
       " 'jancuk',\n",
       " 'janggal',\n",
       " 'jatuh',\n",
       " 'jatuh sakit',\n",
       " 'jauh',\n",
       " 'jebakan',\n",
       " 'jelaga',\n",
       " 'jelas',\n",
       " 'jelatang',\n",
       " 'jelek',\n",
       " 'jelu',\n",
       " 'jempol kebawah',\n",
       " 'jenaka',\n",
       " 'jengkel',\n",
       " 'jerat',\n",
       " 'jerawat',\n",
       " 'jeritan',\n",
       " 'jeruk nipis',\n",
       " 'jijik',\n",
       " 'jompo',\n",
       " 'jumlah sedikit',\n",
       " 'kabur',\n",
       " 'kabut',\n",
       " 'kacau',\n",
       " 'kadaluarsa',\n",
       " 'kadung',\n",
       " 'kafir',\n",
       " 'kagum',\n",
       " 'kain kafan',\n",
       " 'kaku',\n",
       " 'kalah',\n",
       " 'kalahan',\n",
       " 'kambing hitam',\n",
       " 'kambuh',\n",
       " 'kampungan',\n",
       " 'kandang',\n",
       " 'kandas',\n",
       " 'kanibal',\n",
       " 'kanker',\n",
       " 'kantong sampah',\n",
       " 'kapak',\n",
       " 'kapalan',\n",
       " 'karat',\n",
       " 'kasar',\n",
       " 'kasihan',\n",
       " 'kata kata kasar',\n",
       " 'katastropi',\n",
       " 'keadaan acuh tak acuh',\n",
       " 'keadaan buruk',\n",
       " 'keadaan darurat',\n",
       " 'keadaan pingsan',\n",
       " 'keadaan sulit',\n",
       " 'keanehan',\n",
       " 'keangkuhan',\n",
       " 'kebal',\n",
       " 'kebencian',\n",
       " 'keberanian',\n",
       " 'keberatan',\n",
       " 'keberbahayaan',\n",
       " 'kebetulan',\n",
       " 'kebiadaban',\n",
       " 'kebiasaan',\n",
       " 'kebingungan',\n",
       " 'kebiri',\n",
       " 'kebisingan',\n",
       " 'kebobolan',\n",
       " 'kebocoran',\n",
       " 'kebodohan',\n",
       " 'kebohongan',\n",
       " 'kebosanan',\n",
       " 'kebrutalan',\n",
       " 'kebuntuan',\n",
       " 'keburukan',\n",
       " 'kecabulan',\n",
       " 'kecaman',\n",
       " 'kecanduan',\n",
       " 'kecapaian',\n",
       " 'kecelakaan',\n",
       " 'kecelakaan kapal',\n",
       " 'kecemasan',\n",
       " 'kecemburuan',\n",
       " 'kecenderungan',\n",
       " 'kecenderungan untuk menurun',\n",
       " 'kecerobohan',\n",
       " 'kecewa',\n",
       " 'kecil',\n",
       " 'kecongkakan',\n",
       " 'kecurangan',\n",
       " 'kecurigaan',\n",
       " 'kedangkalan',\n",
       " 'kedengkian',\n",
       " 'keengganan',\n",
       " 'kefanatikan',\n",
       " 'kegagalan',\n",
       " 'keganasan',\n",
       " 'kegarangan',\n",
       " 'kegelapan',\n",
       " 'kegelisahan',\n",
       " 'kegemparan',\n",
       " 'kegemukan',\n",
       " 'kegilaan',\n",
       " 'kegoyangan',\n",
       " 'kegugupan',\n",
       " 'kehabisan',\n",
       " 'kehancuran',\n",
       " 'kehebohan',\n",
       " 'keheranan',\n",
       " 'kehilangan',\n",
       " 'kehilangan keseimbangan',\n",
       " 'kehinaan',\n",
       " 'keinginan pribadi',\n",
       " 'keingkaran',\n",
       " 'keirasionalan',\n",
       " 'kejahatan',\n",
       " 'kejam',\n",
       " 'kejang',\n",
       " 'kejanggalan',\n",
       " 'kejangkitan',\n",
       " 'kejatuhan',\n",
       " 'kejelekan',\n",
       " 'kejengahan',\n",
       " 'kejengkelan',\n",
       " 'keji',\n",
       " 'kejut',\n",
       " 'kekacauan',\n",
       " 'kekakuan',\n",
       " 'kekalahan',\n",
       " 'kekanak kanakan',\n",
       " 'kekecewaan',\n",
       " 'kekecilan',\n",
       " 'kekejaman',\n",
       " 'kekejamannya',\n",
       " 'kekeliruan',\n",
       " 'kekenyangan',\n",
       " 'kekerasan',\n",
       " 'kekerasan pendirian',\n",
       " 'kekeringan',\n",
       " 'kekesalan',\n",
       " 'kekhawatiran',\n",
       " 'kekhilafan',\n",
       " 'kekosongan',\n",
       " 'kekotoran',\n",
       " 'kekuatiran',\n",
       " 'kekurangan',\n",
       " 'kekurangpekaan',\n",
       " 'kelakuan buruk',\n",
       " 'kelalaian',\n",
       " 'kelambanan',\n",
       " 'kelancangan',\n",
       " 'kelangkaan',\n",
       " 'kelaparan',\n",
       " 'kelas dua',\n",
       " 'kelelahan',\n",
       " 'kelemahan',\n",
       " 'kelemahan karena usia tua',\n",
       " 'kelembutan',\n",
       " 'kelesuan',\n",
       " 'keletihan',\n",
       " 'keliru',\n",
       " 'keluar',\n",
       " 'keluhan',\n",
       " 'kelupaan',\n",
       " 'kemacetan',\n",
       " 'kemalangan',\n",
       " 'kemalasan',\n",
       " 'kemandekan',\n",
       " 'kemarahan',\n",
       " 'kemasukan setan',\n",
       " 'kemasyhuran',\n",
       " 'kematian',\n",
       " 'kembali',\n",
       " 'kemelaratan',\n",
       " 'kemenduaan',\n",
       " 'kemerosotan',\n",
       " 'kemiskinan',\n",
       " 'kemunafikan',\n",
       " 'kemunduran',\n",
       " 'kemurkaan',\n",
       " 'kemurungan',\n",
       " 'kemustahilan',\n",
       " 'kendor',\n",
       " 'kendur',\n",
       " 'kenekatan',\n",
       " 'kental',\n",
       " 'kepahitan',\n",
       " 'kepala batu',\n",
       " 'kepala sakit',\n",
       " 'kepatahan',\n",
       " 'kepedaran',\n",
       " 'kependekan',\n",
       " 'kepentingan',\n",
       " 'kepentingan diri sendiri',\n",
       " 'kepicikan',\n",
       " 'keputusasaan',\n",
       " 'keputusasan',\n",
       " 'keracunan',\n",
       " 'keraguan',\n",
       " 'kerangka',\n",
       " 'keras',\n",
       " 'keras hati',\n",
       " 'keras kepala',\n",
       " 'keras kapal',\n",
       " 'kerasnya',\n",
       " 'kerdil',\n",
       " 'kere',\n",
       " 'kerepotan',\n",
       " 'kereta',\n",
       " 'keretakan',\n",
       " 'keriangan',\n",
       " 'keributan',\n",
       " 'kerinduan',\n",
       " 'kering',\n",
       " 'keriput',\n",
       " 'keriuhan',\n",
       " 'kerlip',\n",
       " 'keroncongan',\n",
       " 'kerugian',\n",
       " 'kerusakan',\n",
       " 'kerusuhan',\n",
       " 'kerut',\n",
       " 'keruwetan',\n",
       " 'kesal',\n",
       " 'kesalahan',\n",
       " 'kesalahan besar',\n",
       " 'kesalahan hitung',\n",
       " 'kesalahpahaman',\n",
       " 'kesamaan',\n",
       " 'kesedihan',\n",
       " 'keseganan',\n",
       " 'kesegeraan',\n",
       " 'kesembronoan',\n",
       " 'kesendirian',\n",
       " 'kesengitan',\n",
       " 'kesengsaraan',\n",
       " 'kesepian',\n",
       " 'keserakahan',\n",
       " 'keseriusan',\n",
       " 'kesesakan',\n",
       " 'kesilauan',\n",
       " 'kesombongan',\n",
       " 'kesulitan',\n",
       " 'kesuraman',\n",
       " 'kesyahidan',\n",
       " 'ketabahan',\n",
       " 'ketakberanian',\n",
       " 'ketakutan',\n",
       " 'ketamakan',\n",
       " 'ketat',\n",
       " 'ketegangan',\n",
       " 'ketenangan',\n",
       " 'keterbatasan',\n",
       " 'keterbelakangan',\n",
       " 'keterlaluan',\n",
       " 'ketiadaan',\n",
       " 'ketiadaan rasa hormat',\n",
       " 'ketidakabsahan',\n",
       " 'ketidakadilan',\n",
       " 'ketidakakuratan',\n",
       " 'ketidakamanan',\n",
       " 'ketidakbahagiaan',\n",
       " 'ketidakberdayaan',\n",
       " 'ketidakbijaksanaan',\n",
       " 'ketidakcakapan',\n",
       " 'ketidakcocokan',\n",
       " 'ketidakcukupan',\n",
       " 'ketidakefektifan',\n",
       " 'ketidakefisienan',\n",
       " 'ketidakjelasan',\n",
       " 'ketidakjujuran',\n",
       " 'ketidakkasihan',\n",
       " 'ketidaklogisan',\n",
       " 'ketidakmampuan',\n",
       " 'ketidakmampuan menyesuaikan diri',\n",
       " 'ketidakmungkinan',\n",
       " 'ketidakmurnian',\n",
       " 'ketidakpantasan',\n",
       " 'ketidakpedulian',\n",
       " 'ketidakpercayaan',\n",
       " 'ketidakpuasan',\n",
       " 'ketidakrelevanan',\n",
       " 'ketidaksabaran',\n",
       " 'ketidaksamaan',\n",
       " 'ketidakseimbangan',\n",
       " 'ketidaksempurnaan',\n",
       " 'ketidaksenangan',\n",
       " 'ketidaksenonohan',\n",
       " 'ketidaksetaraan',\n",
       " 'ketidaksetiaan',\n",
       " 'ketidaksopanan',\n",
       " 'ketidakstabilan',\n",
       " 'ketidaktahuan',\n",
       " 'ketidaktelitian',\n",
       " 'ketidakteraturan',\n",
       " 'ketidaktertarikan',\n",
       " 'ketidaktoleranan',\n",
       " 'ketidaktulusan',\n",
       " 'ketinggalan',\n",
       " 'ketukan',\n",
       " 'ketus',\n",
       " 'kewajiban',\n",
       " 'kewalahan',\n",
       " 'kezaliman',\n",
       " 'khawatir',\n",
       " 'khayalan',\n",
       " 'khayalan belaka',\n",
       " 'khayali',\n",
       " 'khianat',\n",
       " 'khusus',\n",
       " 'kiamat',\n",
       " 'kikir',\n",
       " 'kikuk',\n",
       " 'kios',\n",
       " 'kisi',\n",
       " 'klik',\n",
       " 'klise',\n",
       " 'knalpot',\n",
       " 'kolot',\n",
       " 'kompatibel',\n",
       " 'kompleks',\n",
       " 'komplikasi',\n",
       " 'komplotan',\n",
       " 'kompong',\n",
       " 'konflik',\n",
       " 'konfrontasi',\n",
       " 'kongkalikong',\n",
       " 'konservatif',\n",
       " 'konsesi',\n",
       " 'konspirasi',\n",
       " 'konspiratif',\n",
       " 'konspirator',\n",
       " 'kontaminasi',\n",
       " 'kontensius',\n",
       " 'kontol',\n",
       " 'kontra',\n",
       " 'kontra produktif',\n",
       " 'kontradiksi',\n",
       " 'kontradiktif',\n",
       " 'kontraproduktif',\n",
       " 'kontroversi',\n",
       " 'kontroversial',\n",
       " 'konyol',\n",
       " 'korban',\n",
       " 'korban kecelakaan',\n",
       " 'korosi',\n",
       " 'korosif',\n",
       " 'korup',\n",
       " 'korupsi',\n",
       " 'kotor',\n",
       " 'kotoran',\n",
       " 'kram',\n",
       " 'krisis',\n",
       " 'kritik',\n",
       " 'kritikus',\n",
       " 'kritis',\n",
       " 'kronis',\n",
       " 'kuat',\n",
       " 'kuatir',\n",
       " 'kucam',\n",
       " 'kucing gemuk',\n",
       " 'kudung',\n",
       " 'kukuh',\n",
       " 'kuning',\n",
       " 'kuno',\n",
       " 'kupas',\n",
       " 'kurang',\n",
       " 'kurang ajar',\n",
       " 'kurang baik',\n",
       " 'kurang berkembang',\n",
       " 'kurang beruntung',\n",
       " 'kurang dikenal',\n",
       " 'kurang lengkap',\n",
       " 'kurang menarik',\n",
       " 'kurang pengalaman',\n",
       " 'kurang sehat',\n",
       " 'kurang sopan',\n",
       " 'kurus',\n",
       " 'kusut',\n",
       " 'kutukan',\n",
       " 'labil',\n",
       " 'labu',\n",
       " 'lacur',\n",
       " 'lalai',\n",
       " 'lalim',\n",
       " 'lama',\n",
       " 'lamban',\n",
       " 'lambat',\n",
       " 'lancang',\n",
       " 'lancar',\n",
       " 'lapis kedua',\n",
       " 'lapuk',\n",
       " 'larangan',\n",
       " 'larut',\n",
       " 'latency',\n",
       " 'lawan',\n",
       " 'lebam',\n",
       " 'lebih buruk',\n",
       " 'lebih keras',\n",
       " 'lebih mahal',\n",
       " 'lebihan',\n",
       " 'lecet',\n",
       " 'ledakan',\n",
       " 'lekat',\n",
       " 'lekir',\n",
       " 'lekuk',\n",
       " 'lelah',\n",
       " 'lelucon',\n",
       " 'lemah',\n",
       " 'lemak',\n",
       " 'lemak kucing',\n",
       " 'lemas',\n",
       " 'lembab',\n",
       " 'lembek',\n",
       " 'lemot',\n",
       " 'lendir',\n",
       " 'lengkap',\n",
       " 'lengket',\n",
       " 'lepas',\n",
       " 'lereng',\n",
       " 'lesu',\n",
       " 'letih',\n",
       " 'letusan',\n",
       " 'liar',\n",
       " ...]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opinion_words_negatif = list(dict.fromkeys(opinion_words_negatif))\n",
    "opinion_words_negatif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "47cdfffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Melakukan TF - IDF\n",
    "vectorizer = TfidfVectorizer(vocabulary=opinion_words_negatif)\n",
    "\n",
    "X_new = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a34f71a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2213x2389 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3227 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3f9fcf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf = pd.DataFrame(X_new.todense(), columns=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ecd4802a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abnormal</th>\n",
       "      <th>absurd</th>\n",
       "      <th>acak</th>\n",
       "      <th>acak acakan</th>\n",
       "      <th>acuh</th>\n",
       "      <th>acuh tak acuh</th>\n",
       "      <th>adiktif</th>\n",
       "      <th>adil</th>\n",
       "      <th>agresi</th>\n",
       "      <th>agresif</th>\n",
       "      <th>...</th>\n",
       "      <th>virus</th>\n",
       "      <th>volatil</th>\n",
       "      <th>vulgar</th>\n",
       "      <th>wabah</th>\n",
       "      <th>waria</th>\n",
       "      <th>was was</th>\n",
       "      <th>waspada</th>\n",
       "      <th>wastafel</th>\n",
       "      <th>ya silahkan saja</th>\n",
       "      <th>yahudi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2208</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2209</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2210</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2211</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2212</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2213 rows Ã— 2389 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      abnormal  absurd  acak  acak acakan  acuh  acuh tak acuh  adiktif  adil  \\\n",
       "0          0.0     0.0   0.0          0.0   0.0            0.0      0.0   0.0   \n",
       "1          0.0     0.0   0.0          0.0   0.0            0.0      0.0   0.0   \n",
       "2          0.0     0.0   0.0          0.0   0.0            0.0      0.0   0.0   \n",
       "3          0.0     0.0   0.0          0.0   0.0            0.0      0.0   0.0   \n",
       "4          0.0     0.0   0.0          0.0   0.0            0.0      0.0   0.0   \n",
       "...        ...     ...   ...          ...   ...            ...      ...   ...   \n",
       "2208       0.0     0.0   0.0          0.0   0.0            0.0      0.0   0.0   \n",
       "2209       0.0     0.0   0.0          0.0   0.0            0.0      0.0   0.0   \n",
       "2210       0.0     0.0   0.0          0.0   0.0            0.0      0.0   0.0   \n",
       "2211       0.0     0.0   0.0          0.0   0.0            0.0      0.0   0.0   \n",
       "2212       0.0     0.0   0.0          0.0   0.0            0.0      0.0   0.0   \n",
       "\n",
       "      agresi  agresif  ...  virus  volatil  vulgar  wabah  waria  was was  \\\n",
       "0        0.0      0.0  ...    0.0      0.0     0.0    0.0    0.0      0.0   \n",
       "1        0.0      0.0  ...    0.0      0.0     0.0    0.0    0.0      0.0   \n",
       "2        0.0      0.0  ...    0.0      0.0     0.0    0.0    0.0      0.0   \n",
       "3        0.0      0.0  ...    0.0      0.0     0.0    0.0    0.0      0.0   \n",
       "4        0.0      0.0  ...    0.0      0.0     0.0    0.0    0.0      0.0   \n",
       "...      ...      ...  ...    ...      ...     ...    ...    ...      ...   \n",
       "2208     0.0      0.0  ...    0.0      0.0     0.0    0.0    0.0      0.0   \n",
       "2209     0.0      0.0  ...    0.0      0.0     0.0    0.0    0.0      0.0   \n",
       "2210     0.0      0.0  ...    0.0      0.0     0.0    0.0    0.0      0.0   \n",
       "2211     0.0      0.0  ...    0.0      0.0     0.0    0.0    0.0      0.0   \n",
       "2212     0.0      0.0  ...    0.0      0.0     0.0    0.0    0.0      0.0   \n",
       "\n",
       "      waspada  wastafel  ya silahkan saja  yahudi  \n",
       "0         0.0       0.0               0.0     0.0  \n",
       "1         0.0       0.0               0.0     0.0  \n",
       "2         0.0       0.0               0.0     0.0  \n",
       "3         0.0       0.0               0.0     0.0  \n",
       "4         0.0       0.0               0.0     0.0  \n",
       "...       ...       ...               ...     ...  \n",
       "2208      0.0       0.0               0.0     0.0  \n",
       "2209      0.0       0.0               0.0     0.0  \n",
       "2210      0.0       0.0               0.0     0.0  \n",
       "2211      0.0       0.0               0.0     0.0  \n",
       "2212      0.0       0.0               0.0     0.0  \n",
       "\n",
       "[2213 rows x 2389 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8a624779",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_array = np.array(X_new.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "90307482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2213, 2389)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "db296b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from niapy.problems import Problem\n",
    "from niapy.task import Task\n",
    "from niapy.algorithms.basic import ParticleSwarmOptimization\n",
    "\n",
    "\n",
    "class SVMFeatureSelection(Problem):\n",
    "    def __init__(self, X_train, y_train, alpha=0.99):\n",
    "        super().__init__(dimension=X_train.shape[1], lower=0, upper=1)\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def _evaluate(self, x):\n",
    "        selected = x > 0.5\n",
    "        num_selected = selected.sum()\n",
    "        if num_selected == 0:\n",
    "            return 1.0\n",
    "        accuracy = cross_val_score(SVC(), self.X_train[:, selected], self.y_train, cv=10, n_jobs=-1).mean()\n",
    "        score = 1 - accuracy\n",
    "        num_features = self.X_train.shape[1]\n",
    "        return self.alpha * score + (1 - self.alpha) * (num_selected / num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b4ef29ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_array = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "47e37b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "748bd10b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [68]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m task \u001b[38;5;241m=\u001b[39m Task(problem, max_iters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m      5\u001b[0m algorithm \u001b[38;5;241m=\u001b[39m ParticleSwarmOptimization(population_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1234\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m best_features, best_fitness \u001b[38;5;241m=\u001b[39m \u001b[43malgorithm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m selected_features \u001b[38;5;241m=\u001b[39m best_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of selected features:\u001b[39m\u001b[38;5;124m'\u001b[39m, selected_features\u001b[38;5;241m.\u001b[39msum())\n",
      "File \u001b[1;32mD:\\venv\\lib\\site-packages\\niapy\\algorithms\\algorithm.py:357\u001b[0m, in \u001b[0;36mAlgorithm.run\u001b[1;34m(self, task)\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m threading\u001b[38;5;241m.\u001b[39mcurrent_thread() \u001b[38;5;241m==\u001b[39m threading\u001b[38;5;241m.\u001b[39mmain_thread() \u001b[38;5;129;01mand\u001b[39;00m multiprocessing\u001b[38;5;241m.\u001b[39mcurrent_process()\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMainProcess\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 357\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexception \u001b[38;5;241m=\u001b[39m e\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\venv\\lib\\site-packages\\niapy\\algorithms\\algorithm.py:353\u001b[0m, in \u001b[0;36mAlgorithm.run\u001b[1;34m(self, task)\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Start the optimization.\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \n\u001b[0;32m    340\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    350\u001b[0m \n\u001b[0;32m    351\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 353\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m r[\u001b[38;5;241m0\u001b[39m], r[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m task\u001b[38;5;241m.\u001b[39moptimization_type\u001b[38;5;241m.\u001b[39mvalue\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mD:\\venv\\lib\\site-packages\\niapy\\algorithms\\algorithm.py:333\u001b[0m, in \u001b[0;36mAlgorithm.run_task\u001b[1;34m(self, task)\u001b[0m\n\u001b[0;32m    331\u001b[0m algo, xb, fxb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miteration_generator(task), \u001b[38;5;28;01mNone\u001b[39;00m, np\u001b[38;5;241m.\u001b[39minf\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task\u001b[38;5;241m.\u001b[39mstopping_condition():\n\u001b[1;32m--> 333\u001b[0m     xb, fxb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43malgo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    334\u001b[0m     task\u001b[38;5;241m.\u001b[39mnext_iter()\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xb, fxb\n",
      "File \u001b[1;32mD:\\venv\\lib\\site-packages\\niapy\\algorithms\\algorithm.py:313\u001b[0m, in \u001b[0;36mAlgorithm.iteration_generator\u001b[1;34m(self, task)\u001b[0m\n\u001b[0;32m    311\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m xb, fxb\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 313\u001b[0m     pop, fpop, xb, fxb, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfpop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfxb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m xb, fxb\n",
      "File \u001b[1;32mD:\\venv\\lib\\site-packages\\niapy\\algorithms\\basic\\pso.py:252\u001b[0m, in \u001b[0;36mParticleSwarmAlgorithm.run_iteration\u001b[1;34m(self, task, pop, fpop, xb, fxb, **params)\u001b[0m\n\u001b[0;32m    250\u001b[0m v[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_velocity(v[i], pop[i], personal_best[i], xb, w, min_velocity, max_velocity, task)\n\u001b[0;32m    251\u001b[0m pop[i] \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mrepair(pop[i] \u001b[38;5;241m+\u001b[39m v[i], rng\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrng)\n\u001b[1;32m--> 252\u001b[0m fpop[i] \u001b[38;5;241m=\u001b[39m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fpop[i] \u001b[38;5;241m<\u001b[39m personal_best_fitness[i]:\n\u001b[0;32m    254\u001b[0m     personal_best[i], personal_best_fitness[i] \u001b[38;5;241m=\u001b[39m pop[i]\u001b[38;5;241m.\u001b[39mcopy(), fpop[i]\n",
      "File \u001b[1;32mD:\\venv\\lib\\site-packages\\niapy\\task.py:145\u001b[0m, in \u001b[0;36mTask.eval\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39minf\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevals \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 145\u001b[0m x_f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproblem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimization_type\u001b[38;5;241m.\u001b[39mvalue\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x_f \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_f \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimization_type\u001b[38;5;241m.\u001b[39mvalue:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_f \u001b[38;5;241m=\u001b[39m x_f \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimization_type\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[1;32mD:\\venv\\lib\\site-packages\\niapy\\problems\\problem.py:57\u001b[0m, in \u001b[0;36mProblem.evaluate\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdimension:\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDimensions do not match. \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m != \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdimension))\n\u001b[1;32m---> 57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [65]\u001b[0m, in \u001b[0;36mSVMFeatureSelection._evaluate\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_selected \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m---> 18\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSVC\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     19\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m accuracy\n\u001b[0;32m     20\u001b[0m num_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mD:\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:509\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    507\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 509\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mD:\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:267\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    266\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 267\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    286\u001b[0m _warn_about_fit_failures(results, error_score)\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\venv\\lib\\site-packages\\joblib\\parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1053\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1056\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1058\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32mD:\\venv\\lib\\site-packages\\joblib\\parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    934\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 935\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    936\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32mD:\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\andyk\\appdata\\local\\programs\\python\\python38\\lib\\concurrent\\futures\\_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 439\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    442\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\users\\andyk\\appdata\\local\\programs\\python\\python38\\lib\\threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 302\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    303\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_array, y_array, test_size=0.3, stratify=y, random_state=1234)\n",
    "\n",
    "problem = SVMFeatureSelection(X_train, y_train)\n",
    "task = Task(problem, max_iters=100)\n",
    "algorithm = ParticleSwarmOptimization(population_size=10, seed=1234)\n",
    "best_features, best_fitness = algorithm.run(task)\n",
    "\n",
    "selected_features = best_features > 0.5\n",
    "print('Number of selected features:', selected_features.sum())\n",
    "print('Selected features:', ', '.join(feature_names[selected_features].tolist()))\n",
    "\n",
    "model_selected = SVC()\n",
    "model_all = SVC()\n",
    "\n",
    "model_selected.fit(X_train[:, selected_features], y_train)\n",
    "print('Subset accuracy:', model_selected.score(X_test[:, selected_features], y_test))\n",
    "\n",
    "model_all.fit(X_train, y_train)\n",
    "print('All Features Accuracy:', model_all.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7e9131",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
