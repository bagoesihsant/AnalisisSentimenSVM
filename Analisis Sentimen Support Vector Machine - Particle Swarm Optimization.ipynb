{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcc7a85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c03a7b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memuat Data\n",
    "df_data = pd.read_excel(\"D:/Bagoes/GitHub Repository/AnalisisSentimenSVM/Data/Data_Scraping_FemaleDaily_06032022_with_index.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc1ccd90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentimen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, reviewer, review, rating, sentimen]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menampilkan kolom Data\n",
    "df_data.head(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "389c0cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menghapus kolom data yang tidak digunakan\n",
    "df_data.drop([\"Unnamed: 0\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db513e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewer</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentimen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [reviewer, review, rating, sentimen]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menampilkan kolom Data\n",
    "df_data.head(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d1f7bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2276, 4)\n"
     ]
    }
   ],
   "source": [
    "# Menampilkan jumlah data dan kolom\n",
    "print(df_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "688c18b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menghapus data tertentu dalam data\n",
    "df_data.drop(index=[41, 82, 119, 139, 199, 213, 216, 236, 243, 276, 278, 317, 351, 379, 407, 444, 608, 707, 886, 945, 946, 1047, 1052, 1076, 1099, 1101, 1126, 1133, 1135, 1149, 1155, 1279, 1419, 1506, 1522, 1535, 1573, 1591, 1611, 1664, 1689, 1725, 1736, 1745, 1756, 1821, 1851, 1870, 1890, 1894, 1906, 1907, 1922, 1956, 1985, 1998, 2141, 2170, 2194, 2197, 2241, 2249, 2258], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab93351c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2213, 4)\n"
     ]
    }
   ],
   "source": [
    "# Menampilkan Jumlah Data\n",
    "print(df_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65829c12",
   "metadata": {},
   "source": [
    "1. Inisialisasi Fungsi Praproses (Preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4171349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import emoji\n",
    "\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10010d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk mengulang kata jika terdapat angka 2 dalam kata tersebut\n",
    "def extract_word_number(text):\n",
    "    extracted_char = \"\"\n",
    "    extra_char = \"\"\n",
    "    \n",
    "    # Check the text length\n",
    "    if len(text) > 1: \n",
    "        # Check if the string contain number 2 as a character\n",
    "        if \"2\" in text:\n",
    "            num_pos = text.index(\"2\")\n",
    "            # Check if theres another character after number 2 character\n",
    "            if len(text[(num_pos + 1):]) > 0:\n",
    "                extra_char = text[(num_pos + 1):]\n",
    "                extracted_char = [text[num] for num in range(num_pos)]\n",
    "                extracted_char = ''.join(extracted_char)\n",
    "                return text.replace(text, \"{0} {0}{1}\".format(extracted_char, extra_char))\n",
    "            else:\n",
    "                extra_char = \"\"\n",
    "                extracted_char = [text[num] for num in range(num_pos)]\n",
    "                extracted_char = ''.join(extracted_char)\n",
    "                return text.replace(text, \"{0} {0}{1}\".format(extracted_char, extra_char))\n",
    "        else:\n",
    "            return text\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8094cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk mengulang kata apabila ada angka 2 dalam bentuk superscript dalam kata\n",
    "def extract_word_superscript(text):\n",
    "    extracted_char = \"\"\n",
    "    extra_char = \"\"\n",
    "    \n",
    "    # Check the text length\n",
    "    if len(text) > 1: \n",
    "        # Check if the string contain number 2 as a character\n",
    "        if \"\\u00b2\" in text:\n",
    "            num_pos = text.index(\"\\u00b2\")\n",
    "            # Check if theres another character after number 2 character\n",
    "            if len(text[(num_pos + 1):]) > 0:\n",
    "                extra_char = text[(num_pos + 1):]\n",
    "                extracted_char = [text[num] for num in range(num_pos)]\n",
    "                extracted_char = ''.join(extracted_char)\n",
    "                return text.replace(text, \"{0} {0}{1}\".format(extracted_char, extra_char))\n",
    "            else:\n",
    "                extra_char = \"\"\n",
    "                extracted_char = [text[num] for num in range(num_pos)]\n",
    "                extracted_char = ''.join(extracted_char)\n",
    "                return text.replace(text, \"{0} {0}{1}\".format(extracted_char, extra_char))\n",
    "        else:\n",
    "            return text\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9b5549b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk menyamakan kata makeup dalam kalimat\n",
    "def make_up_replace(text):\n",
    "    if \"make up\" in text:\n",
    "        return text.replace(\"make up\", \"makeup\")\n",
    "    elif \"make upin\" in text:\n",
    "        return text.replace(\"make upin\", \"makeup\")\n",
    "    elif \"make upnya\" in text:\n",
    "        return text.replace(\"make upnya\", \"makeup\")\n",
    "    elif \"make-up\" in text:\n",
    "        return text.replace(\"make-up\", \"makeup\")\n",
    "    elif \"dimakeup\" in text:\n",
    "        return text.replace(\"dimakeup\", \"makeup\")\n",
    "    elif \"dimakeupin\" in text:\n",
    "        return text.replace(\"dimakeupin\", \"makeup\")\n",
    "    elif \"makeupnya\" in text:\n",
    "        return text.replace(\"makeupnya\", \"makeup\")\n",
    "    elif \"makeupny\" in text:\n",
    "        return text.replace(\"makeupny\", \"makeup\")\n",
    "    elif \"makeupku\" in text:\n",
    "        return text.replace(\"makeupku\", \"makeup\")\n",
    "    elif \"mekap\" in text:\n",
    "        return text.replace(\"mekap\", \"makeup\")\n",
    "    elif \"makeuonya\" in text:\n",
    "        return text.replace(\"makeuonya\", \"makeup\")\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3316dc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk menyamakan kata tzone dalam kalimat\n",
    "def t_zone_replace(text):\n",
    "    if \"t zone\" in text:\n",
    "        return text.replace(\"t zone\", \"tzone\")\n",
    "    elif \"t z\" in text:\n",
    "        return text.replace(\"t z\", \"tzone\")\n",
    "    elif \"t zonenya\" in text:\n",
    "        return text.replace(\"t zonenya\", \"tzone\")\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1011f80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk menyamakan kata bbceam dalam kalimat\n",
    "def bb_cream_replace(text):\n",
    "    if \"bb cream\" in text:\n",
    "        return text.replace(\"bb cream\", \"bbcream\")\n",
    "    else:\n",
    "        return text    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "078793fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk menyamakan kata cccream dalam kalimat\n",
    "def cc_cream_replace(text):\n",
    "    if \"cc cream\" in text:\n",
    "        return text.replace(\"cc cream\", \"cccream\")\n",
    "    else:\n",
    "        return text    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eec6d99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk menyamakan kata dceram dalam kalimat\n",
    "def dd_cream_replace(text):\n",
    "    if \"dd cream\" in text:\n",
    "        return text.replace(\"dd cream\", \"ddcream\")\n",
    "    else:\n",
    "        return text    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61812533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk menyamakan kata touchup dalam kalimat\n",
    "def touch_up_replace(text):\n",
    "    if \"touch up\" in text:\n",
    "        return text.replace(\"touch up\", \"touchup\")\n",
    "    elif \"ngeretouch\" in text:\n",
    "        return text.replace(\"ngeretouch\", \"touchup\")\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7410c890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk menyamakan kata breakout dalam kalimat\n",
    "def break_out_replace(text):\n",
    "    if \"break out\" in text:\n",
    "        return text.replace(\"break out\", \"breakout\")\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a51f44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk menyamakan kata skincare dalam kalimat\n",
    "def skin_care_replace(text):\n",
    "    if \"skin care\" in text:\n",
    "        return text.replace(\"skin care\", \"skincare\")\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b6e1d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk menyamakan kata sunscreen dalam kalimat\n",
    "def sun_screen_replace(text):\n",
    "    if \"sun screen\" in text:\n",
    "        return text.replace(\"sun screen\", \"sunscreen\")\n",
    "    elif \"sunscreenku\" in text:\n",
    "        return text.replace(\"sunscreenku\", \"sunscreen\")\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9af0d0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk mengubah seluruh karakter dalam kalimat menjadi huruf kecil (lowercase)\n",
    "def case_folding(message):\n",
    "    return message.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a998bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk menghapus tanda baca dalam kalimat\n",
    "def del_punctuation(message):\n",
    "    for punc in string.punctuation:\n",
    "        if punc in message:\n",
    "            message = message.replace(punc, ' ')\n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf93d337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk menghapus angka dalam kalimat\n",
    "def del_number(message):\n",
    "    regex = r'\\d+'\n",
    "    return ' '.join(re.sub(regex, \"\", message).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee22defa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk menghapus emotikon dalam kalimat\n",
    "def del_emoticon(message):\n",
    "    return emoji.replace_emoji(message, replace=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e124a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk menghapus kata dengan jumlah huruf yang lebih dari satu dan berdekatan \n",
    "def remove_repeated_char(text):\n",
    "    return re.sub(r'(\\w)\\1+', r'\\1', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3bf1f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk mengubah kata yang menggunakan angka untuk membuat kata berulang\n",
    "def replace_repeat_word_num(message):\n",
    "    split_msg = [word.replace(word, extract_word_number(word)) for word in message.split()]\n",
    "    return \" \".join(split_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1680478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk mengubah kata yang menggunakan angka dalam bentuk superscript untuk membuat kata berulang\n",
    "def replace_repeat_word_superscript(message):\n",
    "    split_msg = [word.replace(word, extract_word_superscript(word)) for word in message.split()]\n",
    "    return \" \".join(split_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "270ea02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk mengubah kata yang memiliki karakter yang sama dan berdekatan dengan jumlah lebih dari satu dalam kalimat\n",
    "def normalisasi_kata_redundan(message):\n",
    "    return remove_repeated_char(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d01e3e4",
   "metadata": {},
   "source": [
    "2. Memuat Corpus Yang Akan Digunakan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2a6a717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c4e299fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memuat Daftar kata dengan jumlah huruf yang sama lebih dari satu dan berdekatan\n",
    "reader_kata_dua_karakter = csv.reader(open(r\"D:/Bagoes/GitHub Repository/AnalisisSentimenSVM/Data/kata_dua_karakter.csv\", \"r\"))\n",
    "\n",
    "dict_kata_dua_karakter = {row[0]:row[1] for row in reader_kata_dua_karakter if row and row[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d359ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memuat daftar kata istilah asing yang tediri dari satu kata\n",
    "reader_satu_kata = csv.reader(open(r\"D:/Bagoes/GitHub Repository/AnalisisSentimenSVM/Data/translasi_satu_kata.csv\", \"r\"))\n",
    "\n",
    "dict_translasi_satu_kata = {row[0]:row[1] for row in reader_satu_kata if row and row[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be626339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memuat daftar kalimat dengan istilah asing\n",
    "reader_lebih_satu_kata = csv.reader(open(r\"D:/Bagoes/GitHub Repository/AnalisisSentimenSVM/Data/translasi_lebih_satu_kata.csv\", \"r\"))\n",
    "\n",
    "result_lebih_satu_kata = {row[0]:row[1] for row in reader_lebih_satu_kata if row and row[0]}\n",
    "\n",
    "# Mengurutkan daftar kalimat istilah asing sesuai dengan panjang kalimat\n",
    "\n",
    "# sorting using sorted()\n",
    "# lambda fnc. to render logic \n",
    "list_lebih_satu_kata = sorted(list(result_lebih_satu_kata.items()), key = lambda key : len(key[0]), reverse=True)\n",
    "\n",
    "# reordering corpus dictionary translasi bahasa lebih satu kata\n",
    "dict_lebih_satu_kata = {val[0] : val[1] for val in list_lebih_satu_kata}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c347a51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memuat daftar kata bahasa alay\n",
    "df_kamus_bahasa_alay = pd.read_csv(r\"D:/Bagoes/GitHub Repository/AnalisisSentimenSVM/Data/colloquial-indonesian-lexicon.csv\")\n",
    "\n",
    "# Membuat Kamus Bahasa Alay\n",
    "list_kata_slang = []\n",
    "\n",
    "for kata_slang in df_kamus_bahasa_alay[\"slang\"]:\n",
    "    list_kata_slang.append(kata_slang)\n",
    "\n",
    "list_kata_formal = []\n",
    "\n",
    "for kata_formal in df_kamus_bahasa_alay[\"formal\"]:\n",
    "    list_kata_formal.append(kata_formal)\n",
    "\n",
    "dict_bahasa_alay = {}\n",
    "\n",
    "for key, value in zip(df_kamus_bahasa_alay[\"slang\"], df_kamus_bahasa_alay[\"formal\"]):\n",
    "    if dict_bahasa_alay.get(key) == None:\n",
    "        dict_bahasa_alay.update({key:value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "14b79dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memuat daftar kata yang mengandung typo (salah dalam penulisan)\n",
    "reader_koreksi_kata = csv.reader(open(r\"D:/Bagoes/GitHub Repository/AnalisisSentimenSVM/Data/koreksi_kata.csv\", \"r\"))\n",
    "\n",
    "dict_koreksi_kata = {row[0]:row[1] for row in reader_koreksi_kata if row and row[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c56bb6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memuat daftar kata yang merupakan stopwords (kata redundan)\n",
    "factory = StopWordRemoverFactory()\n",
    "stopwords_indonesia = factory.get_stop_words()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66ef8f0",
   "metadata": {},
   "source": [
    "3. Membuat Fungsi Untuk Menggunakan Corpus Yang Telah Dimuat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "898537c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk memeriksa apakah token terdapat dalam daftar kata dengan dua karakter yang sama berjumlah lebih dari satu dan berdekatan\n",
    "def check_kata_dua_karakter(text):\n",
    "    for key, val in dict_kata_dua_karakter.items():\n",
    "        if text == key:\n",
    "            text = text.replace(text, dict_kata_dua_karakter.get(key))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a40e8e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk memeriksa apakah token terdapat dalam daftar kata yang akan di translasi\n",
    "def check_translasi_satu_kata(text):\n",
    "    for key, val in dict_translasi_satu_kata.items():\n",
    "        if text == key:\n",
    "            text = text.replace(text, dict_translasi_satu_kata.get(key))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bca4beae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk memeriksa apakah token terdapat dalam daftar kata yang memiliki typo (salah penulisan)\n",
    "def check_koreksi_kata(text):\n",
    "    for key, val in dict_koreksi_kata.items():\n",
    "        if text == key:\n",
    "            text = text.replace(text, dict_koreksi_kata.get(key))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "574ac03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk memeriksa apakah token terdapat dalam daftar kata slang (alay)\n",
    "def check_kata_alay(text):\n",
    "    for key, val in dict_bahasa_alay.items():\n",
    "        if text == key:\n",
    "            text = text.replace(text, dict_bahasa_alay.get(key))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ac1953c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk melakukan normalisasi kalimat menggunakan daftar kata dengan dua karakter yang sama berjumlah lebih dari satu dan berdekatan\n",
    "def normalisasi_kata_dua_karakter(message):\n",
    "    split_text = [check_kata_dua_karakter(text) for text in message.split()]\n",
    "    return \" \".join(split_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "17b4bf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk melakukan normalisasi kalimat menggunakan daftar kalimat yang akan di translasi\n",
    "def normalisasi_translasi_kalimat(message):\n",
    "    for key, val in dict_lebih_satu_kata.items():\n",
    "        if key in message:\n",
    "            message = message.replace(key, dict_lebih_satu_kata.get(key))\n",
    "    return message  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f59c0371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk melakukan normalisasi kalimat menggunakan daftar kata yang akan di translasi\n",
    "def normalisasi_translasi_kata(message):\n",
    "    split_text = [check_translasi_satu_kata(text) for text in message.split()]\n",
    "    return \" \".join(split_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "20ec59d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk melakukan normalisasi kalimat menggunakan daftar kata yang memiliki typo (salah penulisan)\n",
    "def normalisasi_koreksi_kata(message):\n",
    "    split_text = [check_koreksi_kata(text) for text in message.split()]\n",
    "    return \" \".join(split_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4abc3d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk melakukan normalisasi kalimat menggunakan daftar kata slang (alay)\n",
    "def normalisasi_kata_alay(message):\n",
    "    split_text = [check_kata_alay(text) for text in message.split()]\n",
    "    return \" \".join(split_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bcd64cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk menghapus stopwords menggunakan daftar stopwords\n",
    "def del_stopwords(message):\n",
    "    split_text = [text for text in message.split() if text not in stopwords_indonesia]\n",
    "    return \" \".join(split_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f22bb807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memuat Stemmer\n",
    "stem_factory = StemmerFactory()\n",
    "stemmer = stem_factory.create_stemmer()\n",
    "\n",
    "# Fungsi untuk melakukan stemming\n",
    "def stem_words(message):\n",
    "    split_text = [stemmer.stem(text) for text in message.split()]\n",
    "    return \" \".join(split_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "74c5eef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat mapping untuk label data\n",
    "label = {'positif' : 1, 'negatif' : 2}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72e1c5a",
   "metadata": {},
   "source": [
    "4. Tahapan Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ccf78373",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [48]\u001b[0m, in \u001b[0;36m<cell line: 38>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     36\u001b[0m df_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(normalisasi_translasi_kalimat)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# 18. Normalisasi Translasi Kata\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m df_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreview\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormalisasi_translasi_kata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# 19. Normalisasi Koreksi Kata\u001b[39;00m\n\u001b[0;32m     40\u001b[0m df_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(normalisasi_koreksi_kata)\n",
      "File \u001b[1;32mD:\\venv\\lib\\site-packages\\pandas\\core\\series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4324\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4325\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4328\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4329\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4330\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4331\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4332\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4431\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4432\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\venv\\lib\\site-packages\\pandas\\core\\apply.py:1082\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;66;03m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[0;32m   1080\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m-> 1082\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\venv\\lib\\site-packages\\pandas\\core\\apply.py:1137\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1131\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;66;03m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m         \u001b[38;5;66;03m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;66;03m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m         \u001b[38;5;66;03m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;66;03m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[1;32m-> 1137\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1138\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1140\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1144\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mD:\\venv\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Input \u001b[1;32mIn [42]\u001b[0m, in \u001b[0;36mnormalisasi_translasi_kata\u001b[1;34m(message)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnormalisasi_translasi_kata\u001b[39m(message):\n\u001b[1;32m----> 3\u001b[0m     split_text \u001b[38;5;241m=\u001b[39m [check_translasi_satu_kata(text) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m message\u001b[38;5;241m.\u001b[39msplit()]\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(split_text)\n",
      "Input \u001b[1;32mIn [42]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnormalisasi_translasi_kata\u001b[39m(message):\n\u001b[1;32m----> 3\u001b[0m     split_text \u001b[38;5;241m=\u001b[39m [\u001b[43mcheck_translasi_satu_kata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m message\u001b[38;5;241m.\u001b[39msplit()]\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(split_text)\n",
      "Input \u001b[1;32mIn [37]\u001b[0m, in \u001b[0;36mcheck_translasi_satu_kata\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_translasi_satu_kata\u001b[39m(text):\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m dict_translasi_satu_kata\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m text \u001b[38;5;241m==\u001b[39m key:\n\u001b[0;32m      5\u001b[0m             text \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mreplace(text, dict_translasi_satu_kata\u001b[38;5;241m.\u001b[39mget(key))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Melakukan tahapan preprocessing\n",
    "# 1. Case Folding\n",
    "df_data['review'] = df_data['review'].apply(case_folding)\n",
    "# 2. Delete Punctuation\n",
    "df_data['review'] = df_data['review'].apply(del_punctuation)\n",
    "# 3. Delete Emoticon\n",
    "df_data['review'] = df_data['review'].apply(del_emoticon)\n",
    "# 4. Normalisasi Kata Makeup\n",
    "df_data['review'] = df_data['review'].apply(make_up_replace)\n",
    "# 5. Normalisasi Kata TZone\n",
    "df_data['review'] = df_data['review'].apply(t_zone_replace)\n",
    "# 6. Normalisasi Kata BBCream\n",
    "df_data['review'] = df_data['review'].apply(bb_cream_replace)\n",
    "# 7. Normalisasi Kata CCCream\n",
    "df_data['review'] = df_data['review'].apply(cc_cream_replace)\n",
    "# 8. Normalisasi Kata DDCream\n",
    "df_data['review'] = df_data['review'].apply(dd_cream_replace)\n",
    "# 9. Normalisasi Kata Touchup\n",
    "df_data['review'] = df_data['review'].apply(touch_up_replace)\n",
    "# 10. Normalisasi Kata Breakout\n",
    "df_data['review'] = df_data['review'].apply(break_out_replace)\n",
    "# 11. Normalisasi Kata Skin Care\n",
    "df_data['review'] = df_data['review'].apply(skin_care_replace)\n",
    "# 12. Normalisasi Kata Sun Screen\n",
    "df_data['review'] = df_data['review'].apply(sun_screen_replace)\n",
    "# 13. Normalisasi Kata Berulang Dengan Angka\n",
    "df_data['review'] = df_data['review'].apply(replace_repeat_word_num)\n",
    "# 14. Normalisasi Kata Berulang Dengan Angka (Superscript)\n",
    "df_data['review'] = df_data['review'].apply(replace_repeat_word_superscript)\n",
    "# 15. Delete Number\n",
    "df_data['review'] = df_data['review'].apply(del_number)\n",
    "# 16. Normalisasi Kata Dua Karakter Berjumlah Lebih Dari Satu dan Berdekatan\n",
    "df_data['review'] = df_data['review'].apply(remove_repeated_char)\n",
    "df_data['review'] = df_data['review'].apply(normalisasi_kata_dua_karakter)\n",
    "# 17. Normalisasi Translasi Kalimat\n",
    "df_data['review'] = df_data['review'].apply(normalisasi_translasi_kalimat)\n",
    "# 18. Normalisasi Translasi Kata\n",
    "df_data['review'] = df_data['review'].apply(normalisasi_translasi_kata)\n",
    "# 19. Normalisasi Koreksi Kata\n",
    "df_data['review'] = df_data['review'].apply(normalisasi_koreksi_kata)\n",
    "# 20. Normalisasi Kata Slang (Alay)\n",
    "df_data['review'] = df_data['review'].apply(normalisasi_kata_alay)\n",
    "# 21. Delete Stopwords\n",
    "df_data['review'] = df_data['review'].apply(del_stopwords)\n",
    "# 22. Normalisasi Kata (Stemming)\n",
    "df_data['review'] = df_data['review'].apply(stem_words)\n",
    "# 23. Normalisasi Label Data\n",
    "df_data[\"sentimen\"] = df_data[\"sentimen\"].map(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4517e56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e65eab",
   "metadata": {},
   "source": [
    "5. Tahapan Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b600c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import Library\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586890a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Memisahkan data train dengan label\n",
    "X = df_data[\"review\"]\n",
    "y = df_data[\"sentimen\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670262e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73cb5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f3682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de97f471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Melakukan TF - IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X_new = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a4a22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf = pd.DataFrame(X_new.todense(), columns=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f683d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe09fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_array = np.array(X_new.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3182466",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13ff26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from niapy.problems import Problem\n",
    "from niapy.task import Task\n",
    "from niapy.algorithms.basic import ParticleSwarmOptimization\n",
    "\n",
    "\n",
    "class SVMFeatureSelection(Problem):\n",
    "    def __init__(self, X_train, y_train, alpha=0.99):\n",
    "        super().__init__(dimension=X_train.shape[1], lower=0, upper=1)\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def _evaluate(self, x):\n",
    "        selected = x > 0.5\n",
    "        num_selected = selected.sum()\n",
    "        if num_selected == 0:\n",
    "            return 1.0\n",
    "        accuracy = cross_val_score(SVC(), self.X_train[:, selected], self.y_train, cv=10, n_jobs=-1).mean()\n",
    "        score = 1 - accuracy\n",
    "        num_features = self.X_train.shape[1]\n",
    "        return self.alpha * score + (1 - self.alpha) * (num_selected / num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9acbf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_array = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e625ba93",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cba1c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_array, y_array, test_size=0.3, stratify=y, random_state=1234)\n",
    "\n",
    "problem = SVMFeatureSelection(X_train, y_train)\n",
    "task = Task(problem, max_iters=100)\n",
    "algorithm = ParticleSwarmOptimization(population_size=10, seed=1234)\n",
    "best_features, best_fitness = algorithm.run(task)\n",
    "\n",
    "selected_features = best_features > 0.5\n",
    "print('Number of selected features:', selected_features.sum())\n",
    "print('Selected features:', ', '.join(feature_names[selected_features].tolist()))\n",
    "\n",
    "model_selected = SVC()\n",
    "model_all = SVC()\n",
    "\n",
    "model_selected.fit(X_train[:, selected_features], y_train)\n",
    "print('Subset accuracy:', model_selected.score(X_test[:, selected_features], y_test))\n",
    "\n",
    "model_all.fit(X_train, y_train)\n",
    "print('All Features Accuracy:', model_all.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851987a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
